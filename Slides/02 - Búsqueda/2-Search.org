#+title: Search
#+author:
#+email: ddaroch@ing.puc.cl
#+language: en
#+date: AI - 2021 H2
#+REVEAL_ROOT: reveal.js/

* Tasks                                                            :noexport:
** TODO Prepare Slides
** TODO Practice
** TODO Teach
* Config                                                           :noexport:
  #+STARTUP: overview

** Numbering
   #+OPTIONS: toc:nil
   # Remove numbering from sections and subsections
   #+OPTIONS: num:nil

** Reveal
   #+REVEAL_HLEVEL: 2
   #+REVEAL_SPEED: 2
   #+OPTIONS: reveal_slide_number:h.v

   #+REVEAL_EXTRA_CSS: ./style.css

   # Adding plugins without their dependencies might break your slides
   #+REVEAL_EXTRA_JS: { src: 'plugin/math/math.js', async: true }, { src: 'plugin/zoom-js/zoom.js', async: true }
   #+REVEAL_PLUGINS: (highlight markdown notes)

*** Looks
    #+REVEAL_TRANS: slide
    # Theme (black moon night blood)
    #+REVEAL_THEME: black
    # Target 1366x768, 16:9 and not far from 1024x768 widely used on projectors
    #+OPTIONS: reveal_width:1366 reveal_height:768
    # #+REVEAL_EXTRA_CSS: custom.css
*** Reveal
    #+OPTIONS: reveal_center:t
    #+OPTIONS: reveal_progress:t
    #+OPTIONS: reveal_history:nil
    #+OPTIONS: reveal_control:t
    #+OPTIONS: reveal_rolling_links:t
    #+OPTIONS: reveal_keyboard:t
    #+OPTIONS: reveal_overview:t

** Beamer
   #+BEAMER_THEME: Rochester [height=20pt]
   # #+OPTIONS: H:2
   # #+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t

* Search Problem
** Path-finding
   Many interesting problems can be framed as Search problem in a Graph.
   #+ATTR_REVEAL: :frag (appear)
   - Nodes can represent specific states of a system/world/game.
   - Edges represent actions that transform the state from one node into another.
   - Example states:
     - Maze: Coordinates of the player.
     - Chess: Board position, castling state and who's to play.
     - Racing game: Points in $(t, \vec{x}, \vec{v}, \theta, \varphi, Gear, Pedals, Wheel)$.
     - Poker: Cards and chips that each player has.
** Sokoban
  #+REVEAL_HTML: </section>
  #+REVEAL_HTML: <section data-background-iframe="https://www.youtube.com/embed/n9YzAK-nuB4?start=25" data-background-interactive>
** Taxonomy
	#+ATTR_REVEAL: :frag (appear)
	- Mode
 		- Cooperative
 		- Adversarial
	- Knowledge
		- Total
		- Partial
	- Determinism
		- Deterministic environment
		- Non-Deterministic environment
	- Ply (turn) time horizon
		- Real-time
		- Unbounded
** Examples

   |-------------------+-------------+-----------+-------------------+--------------|
   | Game              | Mode        | Knowledge | Determinism       | Time horizon |
   |-------------------+-------------+-----------+-------------------+--------------|
   | Maze              | Cooperative | Total     | Deterministic     | Unbounded    |
   | Sokoban           | Cooperative | Total     | Deterministic     | Unbounded    |
   | Time-trial Racing | Cooperative | Total     | Deterministic     | Real-time    |
   | Freecell          | Cooperative | Partial   | Non-Deterministic | Unbounded    |
   |-------------------+-------------+-----------+-------------------+--------------|

   #+REVEAL: split

   |-------------+-------------+-----------+-------------------+--------------|
   | Game        | Mode        | Knowledge | Determinism       | Time horizon |
   |-------------+-------------+-----------+-------------------+--------------|
   | Racing      | Adversarial | Total     | Deterministic     | Real-time    |
   | Chess       | Adversarial | Total     | Deterministic     | Real-time    |
   | Among Us    | Adversarial | Partial   | Deterministic*    | Real-time    |
   | CS:GO       | Adversarial | Partial   | Deterministic*    | Real-time    |
   | Liar's Dice | Adversarial | Partial   | Non-Deterministic | Real-time    |
   | Uno         | Adversarial | Partial   | Non-Deterministic | Real-time    |
   |-------------+-------------+-----------+-------------------+--------------|

   #+LaTeX: \note{
   #+BEGIN_NOTES
   Enter speaker notes here.
   #+END_NOTES
   #+LaTeX: }

** Problem Terminology
   We will need some common terms to talk about path-finding.
	 #+ATTR_REVEAL: :frag (appear)
   - State: A specific configuration of a system.
     - Chess: The board* and who's to play.
   - Action: An specific action that transforms the system's State.
     - Chess: A move by the active player.
   - Search space: The space where points are system states. Related to the
     ~class~ that represents the state.
     - Chess: A way of representing all chess states, like all [[https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation][FEN]] positions.
   - Search state graph: The graph connecting states through actions.
     - Chess: A huge graph where edges are chess moves from one state to another.

   #+LaTeX: \note{
   #+BEGIN_NOTES
   Chess has some subtleties, like castling and draw by repetition.
   #+END_NOTES
   #+LaTeX: }

** Search terminology
	 #+ATTR_REVEAL: :frag (appear)
   - Search problem: $(Space, start, goal)$
     - Chess start: The state representing the starting board position.
     - Chess goal: A function that checks for check-mates
   - Search Tree: The spanning tree of Nodes representing paths on the State
     graph. Built throughout the Search by adding Nodes or updating edges.
   - Expansion: To compute the possible actions that may be performed and their
     resulting states.

** A generic search algorithm
	 #+ATTR_REVEAL: :frag (appear)
    #+begin_src python
     def generic_search_sketch(g: Graph, starting_node, goal_function) -> Solution:
         Closed = set()  # Closed: Explored nodes (We only store the state)
         Open = MagicalCollection()  # Open: Known, but still unexplored Nodes
         Open.add(starting_node)

         while Open:
             node = Open.pop()  # Takes a node from Open. Which one?
             if is_goal(node):
                 return path(node)

             Closed.add(node)
             for n in node.neighbors():  # Creates Nodes around node.state
                 if n.state in Closed:
                     continue
                  Open.upsert(n)  # Insert|Update to keep Nodes a Spanning Tree (if needed)

         return None
    #+end_src


* Search Algorithms
** Depth-first Search
*** A simple implementation
    #+begin_src python
      def _dfs(g: Graph, state: State, q: Query, p: Path) -> Path:
          """Naive-DFS. Might get stuck in a loop."""
          if q.isGoal(state):
              return p

          for s in g.neighbors(state):
              path = _dfs(g, s, q, p+s)
              if path:
                  return path

          return None

      def dfs(g: Graph, s: State, q: Query):
          return _dfs(g, s, q, Path())
    #+end_src

*** DFS v2 - Loop-safe
    #+begin_src python
      def _loop_free_dfs(g: Graph, state: State, q: Query, p: Path, visited: Set[State]) -> Path:
          """Simple-DFS. Checks for loops, but it might run into a Stack Overflow."""
          if q.isGoal(state):
              return g.path_to(state)  # Retrieve the path to state

          if state in visited
              return None
          visited.add(state)

          for a, s in g.neighbors(state):
              path = _loop_free_dfs(g, s, q, p+a)
              if path:
                  return path

          return None

      def loop_free_dfs(g: Graph, s: State, q: Query) -> Path:
          return _loop_free_dfs(g, s, q, Path(), set())
    #+end_src

*** DFS v3 - Bounded stack
    #+begin_src python
      def loop_free_recursion_free_dfs(g: Graph, start: State, q: Query, p: Path) -> Path:
          """DFS with loop detection and no recursion. Now a Generic Search using a Stack."""
          Closed = set()
          Open = Stack()
          Open.push(start)
          g.reach(start, action=None, parent=None)

          while not Open.empty():
              state = Open.pop()

              if q.isGoal(state):
                  return g.path_to(state)  # Retrieve the path to state

              for a, s in s.neighbors():
                  if s in Closed:
                      continue
                  g.reach(s, action=a, parent=state)  # Update the path to s (if needed)
                  Open.push(s)

          return None
    #+end_src

** Breadth-first Search
*** A simple implementation
    #+begin_src python
      def breadth_first_search(g: Graph, start: State, query: Query) -> Path:
          """BFS. A Generic Search using a Queue."""
          Closed = set()
          Open = Queue()
          Open.push(start)
          g.reach(start, action=None, parent=None)

          while not Open.empty():
              state = Open.pop()

              if q.isGoal(state):
                  return g.path_to(state)  # Retrieve the path to state
      
              for s in state.neighbors():
                  if s in Closed or s in Open:
                      continue
                  g.reach(s, action=a, parent=state)  # Record the path to s (if needed)
                  Open.push(s)

          return None
    #+end_src

** Dijkstra's Algorithm
*** Graphs with costs
    #+ATTR_REVEAL: :frag (appear)
    - Many problems have actions that have different costs.
      - Time or effort actions take varies naturally
        - Some roads are longer, climbing stairs takes more time and energy.
    - BFS won't be optimal in cost by being optimal in the number of actions.

*** Solving problems with cost
    #+ATTR_REVEAL: :frag (appear)
    The natural starting point is BFS as it's optimal in the number of actions.
    #+ATTR_REVEAL: :frag (appear)
    - How do we translate BFS's hop-consiousness into cost-consiousness?
      #+ATTR_REVEAL: :frag (appear)
      - Instead of the closest node you can reach, take the cheapest one.
      - Wait, is that enough? What's so smart about this? How is Dijkstra
        famous for it?
        #+ATTR_REVEAL: :frag (appear)
        - Yes; nothing; Invented it while drinking coffee, and also invented
          many more algorithms.

*** Updating Open
    Costs will force us to continuously rank and update  nodes in $Open$.
    #+begin_src dot :file Graphs/search_update_open.png :results show :exports results
      digraph update_open {
        rankdir=LR;

        s->a [label=1];
        a->g [label=3];

        s->b [label=2];
        b->g [label=0];

        s->g [label=5];
      }
    #+end_src
    We will need something more efficient than a list or a stack.
    - A Priority Queue (aka Heap) does exactly what we need. ([[https://docs.python.org/3/library/heapq.html#theory][Python's heapq]])

*** Updating Open
    What should we do here?
    #+begin_src dot :file Graphs/search_update_open2.png :results show :exports results
      digraph update_open2 {
        rankdir=LR;

        s->a [label=1];
        a->g [label=3];

        s->b [label=0];
        b->c [label=7];
        c->d [label=0];

        s->g [label=5];
      }
    #+end_src
    #+ATTR_REVEAL: :frag (appear)
    - Expansions: $(0, s), (0, b), (1, a), (4, g)$.
    - Insertions/Updates: $[(0, s)], [(1, a), (0, b), (5, g)], [(7, c)], [(5\rightarrow 4, g)]$.
    - Final Closed: ${s, b, a}$. Final Open: $(7, c)$. Unknown States: $d$

*** A simple implementation
    #+begin_src python
      def best_first_search(g: Graph, start: State, query: Query) -> Path:
          """Dijkstra's algorithm. Similar to BFS, but prefering lower costs."""
          Closed = set()
          Open = CustomPriorityQueue()  # A Heap with fast updates for existing items
          Open.push(Node(start))

          while not Open.empty():
              node = Open.pop()

              if q.isGoal(node.state):
                  return node.get_path()

              for a, s in state.neighbors():
                  if s in Closed:
                      continue
                  n = Node(s, action=a, parent=state)
                  Open.update_if_better(n)  # Open may already have a Node for s

          return None
    #+end_src

** Smarter decisions
*** Lack of comprehension
    #+ATTR_REVEAL: :frag (appear)
    - Even while Dijkstra's Algorithm is aware of the costs, it still takes
      decisions that humans looking at a (simple) graph wouldn't.
      - We make good guesses on where to head to, even if we don't exactly know
        the solution for the problem.
    - What do we really think about when solving search problems?
      - We sense that some States are better than others as they seem to be
        closer to the goals.
      - We estimate the remaining cost.

*** What if we could estimate?
    #+ATTR_REVEAL: :frag (appear)
    - Say we had a function $estimate: State \rightarrow \mathbb{R}_0^+$
    - We could tie-break based on the estimated cost.
      - For equally expensive nodes from Open, we would prefer the one that
        seems closer
    - Can we do better?

*** Rethinking costs
    #+ATTR_REVEAL: :frag (appear)
    With a known cost to a Node, and an estimated remaining cost to reach a goal,
    we can guess what's the cost of a solution that goes the Node.
    #+ATTR_REVEAL: :frag (appear)
    - Instead of only ranking with $cost: Node \rightarrow \mathbb{R}_0^+$ we
      can also consider the estimated remaining cost.
      #+ATTR_REVEAL: :frag (appear)
      - $solution\_cost: Node \rightarrow \mathbb{R}_0^+$
      - $solution\_cost(n) = cost(n) + estimate(n.state)$
      - Actually known as $f(n) = g(n) + h(n.state)$

*** Heuristics
    #+ATTR_REVEAL: :frag (appear)
    - How do we estimate costs of a path we don't know yet?
    - What if we estimate costs poorly?
      - What's a poor estimation?
        - $h(s) = 0$ is a function from $State \rightarrow \mathbb{R}_0^+$.
          - With this we are back to using Dijkstra's algorithm?
        - What if we under-estimate the cost?
        - What if we over-estimate the cost?
        - Can we improve our estimations as we go?

*** A*
    #+ATTR_REVEAL: :frag (appear)
    $A^*$ is the search algorithm that ranks nodes with $f(n)=g(n)+h(n.state)$.
    #+ATTR_REVEAL: :frag (appear)
    - Is it better? Is it the best?
      #+ATTR_REVEAL: :frag (appear)
      - Well, it depends on how good the heuristic is.

*** What's a good heuristic?
    #+ATTR_REVEAL: :frag (appear)
    - $h(s)=0$ is definitely not good.
      #+ATTR_REVEAL: :frag (appear)
      - Not the worst, at least you fallback to Dijkstra's Algorithm, which works and gets optimal solutions.
      - Really? What's worse than $h(s)=0$?
        #+ATTR_REVEAL: :frag (appear)
        - A misguiding heuristic. What if $h(g)=\infty$ for every goal state?
          #+ATTR_REVEAL: :frag (appear)
          - [[https://youtu.be/vde6rOO5AbU?t=32][That's evil]]! With that we would miss the goal!
          - True. With bad heuristics $A^*$ may not be complete nor correct.
    #+ATTR_REVEAL: :frag (appear)
    - If $h(s)$ was the actual cost to the solution it would be really good.
      #+ATTR_REVEAL: :frag (appear)
      - Indeed, but computing that is solving the search problem at hand.
      - This perfect heuristic, called $h^*(s)$, is a good reference heuristic.

*** So, what's a good heuristic?
    #+ATTR_REVEAL: :frag (appear)
    - A good heuristic must not drive us away from a goal.
      #+ATTR_REVEAL: :frag (appear)
      - $0 \leq h(s) \leq h^*(s)$
        #+ATTR_REVEAL: :frag (appear)
        - Global property that ensures $f(n)$ is always be a lower bound for the cost.
        - Otherwise we may defer expanding nodes in the optimal path for too
          long and find a sub-optimal path first.
        - Known as admissibility.
      - Is this enough?
        - No :(

*** A stronger heuristic property
    #+begin_src dot :file Graphs/search_inconsistent_h.png :results show :exports results
      digraph inconsistent_h {
        rankdir=LR;

        s [label="S\nh=4"];
        a [label="A\nh=3"];
        b [label="B\nh=0"];
        g [label="G\nh=0"];

        s->a [label=1];
        s->b [label=3];
        a->b [label=1];
        b->g [label=2];
      }
    #+end_src

    [[file:Graphs/search_inconsistent_h.png]]

    #+ATTR_REVEAL: :frag (appear)
    - $A^*$ finds $[S, B, G]$ with cost $5$, which is suboptimal.
      - Please see it by yourself.
    - This heuristic is admissible and almost $h^*(s)$, it only differs on $B$.
      #+ATTR_REVEAL: :frag (appear)
      - $A^*$ gets misdirected. What's so wrong with $h(B)=0$?
        - It tells us that $B$ is really good and $B$ gets in $Closed$ too early.
        - When we expand $A$ we could notice there's something odd.

*** Consistency
    [[file:Graphs/search_inconsistent_h.png]]
    #+ATTR_REVEAL: :frag (appear)
    - The oddity must be on $h(B)=0$. On other states $h=h^*$.
      #+ATTR_REVEAL: :frag (appear)
      - BFS and Dijkstra expand nodes with non-decreasing steps / cost.
      - But this glitch in $h(B)$ makes $f(S)=4$ drop down to $f(B)=3$
    - Consistency:
      #+ATTR_REVEAL: :frag (appear)
      - Local property that justifies h(s) considering the successors of $s$.
      - $h(n) \leq c(n, a, n') + h(n')$
      - $g(n) + h(n) \leq g(n) + c(n, a, n') + h(n')$
      - $f(n) \leq f(n')$

*** Optimality
    #+ATTR_REVEAL: :frag (appear)
    - Is $A^*$ finally optimal when using a consistent heuristic?
      #+ATTR_REVEAL: :frag (appear)
      - Yes, and we can get a slightly more general result for free.
      - w-$A^*$ is w-optimal.
        #+ATTR_REVEAL: :frag (appear)
        - $f_w(n) = g(s) + w*h(n)$ produces solutions no more than $w$ times
          more expensive than the optimal.
        - This makes the fringe deform even further towards the goals.

*** Engineering heuristics
    #+ATTR_REVEAL: :frag (appear)
    - We can disassemble a problem without affecting the heuristic properties.
      #+ATTR_REVEAL: :frag (appear)
      - Removing an action/edge keeps a heuristic admissible.
      - Removing an action/edge keeps a heuristic consistent.
    - Can we devise a problem with more actions and solve it perfectly?
      #+ATTR_REVEAL: :frag (appear)
      - This problem is called a relaxation.
      - Solving it with a consistent heuristic, like $h^*$ would give us a
        consistent (and admissible) heuristic for our actual problem.

** Designing heuristics

*** 2D-grid
    |üßç|#| | |#|üèÅ|
    | |#| | |#| |
    | | | | |#| |
    | |#|#| | | |
    | | | |#|#| |
    | | | | | | |

*** 8-puzzle
    | 1 | 2 | 3 |
    | 4 | 5 | 8 |
    |   | 7 | 6 |

    [[https://murhafsousli.github.io/8puzzle/][Online 8-Puzzle]]

*** Sokoban
    |üßç|üß±| | | |‚òê|
    | |üß±| | |üß±|üß±|
    | |üß±| | |üß±|‚òê|
    | |üß±| | |üß±| |
    | |üß±| | üì¶ | üì¶ | |
    | | | | | | |

    #+REVEAL_HTML: </section>
    #+REVEAL_HTML: <section data-background-iframe="https://www.youtube.com/embed/n9YzAK-nuB4?start=25" data-background-interactive>

*** Sudoku
    # | | |5||3| | || | | |
    # |8| | || | | || |2| |
    # | |7| || |1| ||5| | |
    # |-----||-----||-----|
    # |-----||-----||-----|
    # |4| | || | |5||3| | |
    # | |1| || |7| || | |6|
    # | | |3||2| | || |8| |
    # |-----||-----||-----|
    # |-----||-----||-----|
    # | |6| ||5| | || | |9|
    # | | |4|| | | || |3| |
    # | | | || | |9||7| | |

    [[file:./Images/sudoku.png]]

*** Unblock-me

    [[file:./Images/unblock-me.png]]

*** Parking lot
    #+REVEAL_HTML: </section>
    #+REVEAL_HTML: <section data-background-iframe="https://www.youtube.com/embed/CMKbmmehgj8" data-background-interactive>

** Topics in Search
*** Iterative deepening
    - Most search trees grow exponentially as their depth increases.
      - Without $h^*$, no matter how we choose, we will run into huge trees.
      - Can we explore the search tree without generating too many nodes?
        - Memory is slow
        - CPUs are super fast, we will likely be bounded by the CPU cache and
          main memory speeds.

*** Iterative deepening
 	 #+ATTR_REVEAL: :frag (appear)
     #+begin_src python
     def generic_search_sketch(g: Graph, starting_node, goal_function, limit) -> Solution:
         Closed = set()  # Closed: Explored nodes (We only store the state)
         Open = MagicalCollection()  # Open: Known, but still unexplored Nodes
         Open.add(starting_node)

         while Open:
             node = Open.pop()  # Takes a node from Open. Which one?
             if node.cost > limit:
                 continue
             if is_goal(node):
                 return path(node)
             Closed.add(node)
             for n in node.neighbors():  # Creates Nodes around node.state
                 if n.state in Closed:
                     continue
                  Open.upsert(n)  # Insert|Update to keep Nodes a Spanning Tree (if needed)

         return None

     def generic_search_sketch(g: Graph, starting_node, goal_function) -> Solution:
         limit = 1
         while True:
             sol = generic_search(g, starting_node, goal_function, limit)
             if sol is not None:
                 return sol

             limit += # ???
     #+end_src

*** Monte-Carlo tree search
    - What if simulating games was cheaper than thinking?
      - We could play randomly and remember the best solutions so far
        - Early cut-off
        - Having a solution ready early on
          - If we run out of time we'll probably have something.

*** Online search
    - Interleaving thinking and acting.
      - Does this really work?
        - How to avoid loops?
      - Can we learn across search iterations?
    - When can we effectively do this?
      - What if some actions were irreversible?

*** Online Search - The bad parts
    | | | | |G| | | | |
    | |#|#|#|#|#|#|#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | |S| | |#| |
    | | | | | | | | | |

*** Online Search - The bad parts
    | | | | |G| | | | |
    | |#|#|#|#|#|#|#| |
    | |#|-|X|x|X|-|#| |
    | |#|-|-|-|-|-|#| |
    | |#|-|-|-|-|-|#| |
    | |#| |-|-|-| |#| |
    | |#| | |-| | |#| |
    | |#| | |-| | |#| |
    | |#| | |S| | |#| |
    | | | | | | | | | |

*** Online Search - The bad parts
    | | | | |G| | | | |
    | |#|#|#|#|#|#|#| |
    | |#| | |s| | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | | | | | | | | | |

*** Online Search - The bad parts
    | | | | |G| | | | |
    | |#|#|#|#|#|#|#| |
    | |#|-|-|s|-|-|#| |
    | |#|-|-|-|-|-|#| |
    | |#|-|-|-|-|-|#| |
    | |#|X|-|-|-|X|#| |
    | |#|x|X|-|X|x|#| |
    | |#| |x|X|x| |#| |
    | |#| | |x| | |#| |
    | | | | | | | | | |

*** Online Search - The bad parts
    | | | | |G| | | | |
    | |#|#|#|#|#|#|#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | | | | |#| |
    | |#| | |S| | |#| |
    | | | | | | | | | |

* Adversarial Search
** What is adversarial search?
*** A planned disruption
    #+ATTR_REVEAL: :frag (appear)
    - So far we have studied methods to solve games where everything is under control
      #+ATTR_REVEAL: :frag (appear)
      - We make every move
      - We completely understand and know the consequences of our actions
      - We can take as long as we need
    - What if we are not the only agent?
      #+ATTR_REVEAL: :frag (appear)
      - Games against other smart agents
      - Games against chance

*** Playing against adversaries
    #+ATTR_REVEAL: :frag (appear)
    - How do we play chess?
      #+ATTR_REVEAL: :frag (appear)
      - We need to know how we and our opponents will play.
      - They need to know how we will play too. There's some symmetry.

*** Game trees
    # https://www.researchgate.net/figure/Game-tree-for-Tic-Tac-Toe-game-using-MiniMax-algorithm_fig1_262672371

    [[file:./Images/tic-tac-toe.png]]

*** Representing games
    #+ATTR_REVEAL: :frag (appear)
    - If we ever played tic-tac-toe, we thought about that tree before.
      #+ATTR_REVEAL: :frag (appear)
      - But what is really that tree?

*** Game elements
    #+ATTR_REVEAL: :frag (appear)
    - Space: The space of configurations of the problem and the actions.
      #+ATTR_REVEAL: :frag (appear)
      - Players: This is new, just a list of players.
      - State: A specific state of the game.
        #+ATTR_REVEAL: :frag (appear)
        - Active player: Who is to take an action.
        - Actions: The actions that the active player can take and their
          outcome.
    - Problem: The game to play on the Space
      #+ATTR_REVEAL: :frag (appear)
      - Initial State: Where to start from. This includes the starting player.
      - Terminal test: A predicate that tells us that the game ended.
      - Utility: A function $state, player \to \mathbb{R}$ that tells us the
        outcomes for each player.

*** Minimax
    #+begin_src python
      def minimax(state: State) -> (Action, Score):
          """Selects the action with the best worst-case.

          If our (only) opponent plays perfectly, we maximize our value.
          """
          best_action = None
          best_value = float("-inf")

          for (a, s) in state.neighbors():
              state_value = min_value(s)
              if state_value > best_value:
                  best_value = state_value
                  best_action = a
          return (best_action, best_value)
    #+end_src

*** Minimax helpers
    #+begin_src python
      def max_value(state: State) -> Score:
          """The best outcome we can get."""
          if problem.is_terminal(state):
              return problem.linearized_utility(state)

          best_value = float("-inf")
          for (a, s) in state.neighbors():
              best_value = max(best_value, min_value(s))
          return best_value

      def min_value(state: State) -> Score:
          """The worst outcome we may face."""
          if problem.is_terminal(state):
              return problem.linearized_utility(state)

          worst_value = float("inf")
          for (a, s) in state.neighbors():
              worst_value = min(worst_value, max_value(s))
          return worst_value
    #+end_src

*** Minimax limitations
    #+ATTR_REVEAL: :frag (appear)
    - Minimax never estimates the future moves, it just computes and check them.
    - Exploring the entire search space is too expensive
      #+ATTR_REVEAL: :frag (appear)
      - We don't play games like this!

*** Improving the search
    - Trim actions that won't be played
      - If a player has a good move, why analyze lesser moves?
    - Limit the analysis depth by estimating the value of the states.
      - Many games have infinite game trees. This is a hard requirement.
        - Chess has some special rules to declare draws.
    - Rank actions
      - Prioritizing good moves improves trimming.

*** Alpha-beta pruning
    #+begin_src python
                def alpha_beta_pruning(state: State) -> (Action, Score):
                    """Selects the action with the best worst-case.

                    If our (only) opponent plays perfectly, we maximize our value.
                    s: The state to analyse
                    a: The value of our best move.
                    b: The value of our opponent's worst move.
                    """
                    best_action = None
                    best_value = float("-inf")

                    for (a, s) in state.neighbors():
                        state_value = max_value(s,
                                                alpha=float("-inf"), # We lose
                                                beta=float("inf"))   # They lose
                        if state_value > best_value:
                            best_value = state_value
                            best_action = a
                    return (best_action, best_value)
    #+end_src

*** Alpha-beta pruning helpers
    #+begin_src python
      def max_value(state: State, alpha: Score, beta: Score) -> Score:
          """The best outcome we can get."""
          if problem.is_terminal(state):
              return problem.linearized_utility(state)

          best_value = float("-inf")
          for (a, s) in state.neighbors():
              best_value = max(best_value, min_value(s, alpha_beta))
              if best_value >= beta:  # Our opponent already has a better move
                  return best_value
              alpha = max(alpha, best_value)
          return best_value

      def min_value(state: State, alpha: Score, beta: Score) -> Score:
          """The worst outcome we may face."""
          if problem.is_terminal(state):
              return problem.linearized_utility(state)

          worst_value = float("inf")
          for (a, s) in state.neighbors():
              worst_value = min(worst_value, max_value(s, alpha, beta))
              if worst_value <= alpha:  # We already have a better move
                  return worst_value
              beta = min(beta, worst_value)
          return worst_value
    #+end_src

*** Estimating value
    #+ATTR_REVEAL: :frag (appear)
    - How can we guess the value of a state without exploring the following moves?
      #+ATTR_REVEAL: :frag (appear)
      - This plays the same role as heuristics, but what's a good estimation here?
    - This is problem specific, but it should relate to the chances of winning.
      #+ATTR_REVEAL: :frag (appear)
      - e.g.: Chess: Consider power of each player's pieces, a measure of board control.
    - When do we resort to estimates?
      #+ATTR_REVEAL: :frag (appear)
      - Add a hard-limit to depth. We want a known bound to keep the search finite.
      - Can we dynamically adjust the depth limit based on the state?
        - This needs problem-specific knowledge and experimentation.
    - How do we implement this?
      #+ATTR_REVEAL: :frag (appear)
      - Right after checking for terminal states so we don't explore any further.

*** Ranking actions
    In which order do we explore the actions? How do we rank them?
    #+ATTR_REVEAL: :frag (appear)
    - We may statically rank actions by how powerful they usually are.
      #+ATTR_REVEAL: :frag (appear)
      - e.g.: Chess: Capturing pieces, checks
    - We may rank actions by estimating the value of the states they get to.
      #+ATTR_REVEAL: :frag (appear)
      - This is more dynamic and just reuses the estimating function.
    - Do we need to explore every action?
      #+ATTR_REVEAL: :frag (appear)
      - What if an action ranks too poorly?
      - We can just drop actions just based on our estimation.

*** Further tricks
    Can we analyze the game beforehand?
    #+ATTR_REVEAL: :frag (appear)
    - Many chess engines resort to opening databases
      #+ATTR_REVEAL: :frag (appear)
      - These store good estimates of in-depth analysis. Essentially a cache.
    - Can we capture evaluation knowledge and use it in new searches?
      #+ATTR_REVEAL: :frag (appear)
      - Just throw-in some ML to build a circuit (NN) that precisely and
        concisely evaluates positions from in-depth offline analysis.
        #+ATTR_REVEAL: :frag (appear)
        - We can learn our state evaluation function.
        - We can learn our action ranking and pruning function.
        - We can learn our search cut-off function.

*** Links                                                          :noexport:
    - [[https://math.stackexchange.com/questions/485752/tictactoe-state-space-choose-calculation][TicTacToe State Space Size]]
